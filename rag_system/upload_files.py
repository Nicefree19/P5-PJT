"""
Gemini File Search RAG System - íŒŒì¼ ì—…ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” í”„ë¡œì íŠ¸ í´ë”ì˜ ëª¨ë“  íŒŒì¼ì„ Gemini File Search Storeì— ì—…ë¡œë“œí•˜ì—¬
RAG ì‹œìŠ¤í…œì„ êµ¬ì¶•í•©ë‹ˆë‹¤.

ì§€ì› íŒŒì¼ í˜•ì‹: PDF, Office ë¬¸ì„œ, ì½”ë“œ íŒŒì¼, Markdown, JSON, SQL ë“± 120+ í˜•ì‹
"""

import os
import pathlib
import mimetypes
from typing import List, Dict, Optional
import google.generativeai as genai
from google.generativeai.types import file_types
import time
import json
from datetime import datetime

# ì„¤ì •
GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY')
if not GEMINI_API_KEY:
    raise ValueError("GEMINI_API_KEY í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”")

genai.configure(api_key=GEMINI_API_KEY)

# ì§€ì› íŒŒì¼ í™•ì¥ì (Gemini File Search API ì§€ì› í˜•ì‹)
SUPPORTED_EXTENSIONS = {
    # ë¬¸ì„œ
    '.pdf', '.docx', '.doc', '.xlsx', '.xls', '.pptx', '.ppt',
    '.txt', '.md', '.markdown', '.rtf', '.odt', '.ods', '.odp',

    # ì½”ë“œ
    '.py', '.js', '.ts', '.jsx', '.tsx', '.java', '.cpp', '.c', '.h',
    '.cs', '.rb', '.go', '.rs', '.php', '.swift', '.kt', '.scala',
    '.r', '.m', '.sh', '.bash', '.ps1', '.bat',

    # ë°ì´í„°
    '.json', '.xml', '.yaml', '.yml', '.csv', '.tsv', '.sql',

    # ë§ˆí¬ì—…
    '.html', '.htm', '.css', '.scss', '.sass', '.less',

    # ì„¤ì •
    '.toml', '.ini', '.conf', '.config', '.env',

    # ê¸°íƒ€
    '.log', '.tex', '.bib'
}

# ì œì™¸í•  ë””ë ‰í† ë¦¬
EXCLUDE_DIRS = {
    'node_modules', '.git', '__pycache__', 'venv', 'env',
    '.venv', 'dist', 'build', '.next', '.cache', 'coverage'
}

class GeminiRAGUploader:
    """Gemini File Search Storeì— íŒŒì¼ì„ ì—…ë¡œë“œí•˜ëŠ” í´ë˜ìŠ¤"""

    def __init__(self, store_name: str = "P5_Project_RAG_Store"):
        """
        Args:
            store_name: File Search Store ì´ë¦„
        """
        self.store_name = store_name
        self.store = None
        self.uploaded_files = []
        self.failed_files = []

    def create_or_get_store(self) -> None:
        """File Search Store ìƒì„± ë˜ëŠ” ê¸°ì¡´ Store ê°€ì ¸ì˜¤ê¸°"""
        try:
            # ê¸°ì¡´ Store ëª©ë¡ í™•ì¸
            stores = genai.list_file_search_stores()

            for store in stores:
                if store.display_name == self.store_name:
                    self.store = store
                    print(f"âœ… ê¸°ì¡´ Store ë°œê²¬: {self.store_name}")
                    print(f"   Store ID: {store.name}")
                    return

            # ìƒˆ Store ìƒì„±
            print(f"ğŸ“¦ ìƒˆ File Search Store ìƒì„± ì¤‘: {self.store_name}")
            self.store = genai.create_file_search_store(
                config={'display_name': self.store_name}
            )
            print(f"âœ… Store ìƒì„± ì™„ë£Œ: {self.store.name}")

        except Exception as e:
            print(f"âŒ Store ìƒì„±/ì¡°íšŒ ì‹¤íŒ¨: {e}")
            raise

    def scan_directory(self, directory: str) -> List[pathlib.Path]:
        """
        ë””ë ‰í† ë¦¬ë¥¼ ìŠ¤ìº”í•˜ì—¬ ì—…ë¡œë“œ ê°€ëŠ¥í•œ íŒŒì¼ ëª©ë¡ ë°˜í™˜

        Args:
            directory: ìŠ¤ìº”í•  ë””ë ‰í† ë¦¬ ê²½ë¡œ

        Returns:
            ì—…ë¡œë“œ ê°€ëŠ¥í•œ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        """
        files_to_upload = []
        directory_path = pathlib.Path(directory).resolve()

        print(f"\nğŸ“‚ ë””ë ‰í† ë¦¬ ìŠ¤ìº” ì¤‘: {directory_path}")

        for file_path in directory_path.rglob('*'):
            # ë””ë ‰í† ë¦¬ëŠ” ìŠ¤í‚µ
            if file_path.is_dir():
                continue

            # ì œì™¸ ë””ë ‰í† ë¦¬ ì²´í¬
            if any(excluded in file_path.parts for excluded in EXCLUDE_DIRS):
                continue

            # í™•ì¥ì ì²´í¬
            if file_path.suffix.lower() not in SUPPORTED_EXTENSIONS:
                continue

            # íŒŒì¼ í¬ê¸° ì²´í¬ (100MB ì œí•œ)
            if file_path.stat().st_size > 100 * 1024 * 1024:
                print(f"âš ï¸  íŒŒì¼ í¬ê¸° ì´ˆê³¼ (>100MB): {file_path.name}")
                continue

            files_to_upload.append(file_path)

        print(f"âœ… ë°œê²¬ëœ íŒŒì¼: {len(files_to_upload)}ê°œ")
        return files_to_upload

    def upload_file(self, file_path: pathlib.Path) -> Optional[Dict]:
        """
        ë‹¨ì¼ íŒŒì¼ì„ File Search Storeì— ì—…ë¡œë“œ

        Args:
            file_path: ì—…ë¡œë“œí•  íŒŒì¼ ê²½ë¡œ

        Returns:
            ì—…ë¡œë“œ ê²°ê³¼ ì •ë³´ (ì„±ê³µ ì‹œ) ë˜ëŠ” None (ì‹¤íŒ¨ ì‹œ)
        """
        try:
            # MIME íƒ€ì… ì¶”ì •
            mime_type, _ = mimetypes.guess_type(str(file_path))
            if not mime_type:
                mime_type = 'application/octet-stream'

            # íŒŒì¼ ë©”íƒ€ë°ì´í„°
            metadata = {
                'file_path': str(file_path),
                'file_name': file_path.name,
                'file_type': file_path.suffix[1:],  # .py -> py
                'upload_time': datetime.now().isoformat()
            }

            print(f"â¬†ï¸  ì—…ë¡œë“œ ì¤‘: {file_path.name} ({mime_type})")

            # File Search Storeì— ì§ì ‘ ì—…ë¡œë“œ
            with open(file_path, 'rb') as f:
                operation = genai.upload_to_file_search_store(
                    file=f,
                    file_search_store_name=self.store.name,
                    config={
                        'display_name': file_path.name,
                        'metadata': metadata
                    }
                )

            # ì—…ë¡œë“œ ì™„ë£Œ ëŒ€ê¸°
            while operation.metadata.state == 'STATE_PENDING':
                time.sleep(1)
                operation = genai.get_operation(operation.name)

            if operation.metadata.state == 'STATE_SUCCEEDED':
                result = {
                    'file_path': str(file_path),
                    'file_name': file_path.name,
                    'operation_name': operation.name,
                    'status': 'success'
                }
                self.uploaded_files.append(result)
                print(f"   âœ… ì—…ë¡œë“œ ì„±ê³µ")
                return result
            else:
                raise Exception(f"Operation failed: {operation.metadata.state}")

        except Exception as e:
            print(f"   âŒ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.failed_files.append({
                'file_path': str(file_path),
                'error': str(e)
            })
            return None

    def upload_directory(self, directory: str, max_files: Optional[int] = None) -> None:
        """
        ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  íŒŒì¼ì„ ì—…ë¡œë“œ

        Args:
            directory: ì—…ë¡œë“œí•  ë””ë ‰í† ë¦¬ ê²½ë¡œ
            max_files: ìµœëŒ€ ì—…ë¡œë“œ íŒŒì¼ ìˆ˜ (Noneì´ë©´ ì „ì²´)
        """
        # Store ìƒì„±
        self.create_or_get_store()

        # íŒŒì¼ ìŠ¤ìº”
        files = self.scan_directory(directory)

        if max_files:
            files = files[:max_files]
            print(f"ğŸ“Š ì—…ë¡œë“œí•  íŒŒì¼ ìˆ˜ ì œí•œ: {max_files}ê°œ")

        # ì—…ë¡œë“œ ì‹œì‘
        print(f"\nğŸš€ ì—…ë¡œë“œ ì‹œì‘ ({len(files)}ê°œ íŒŒì¼)")
        print("=" * 60)

        for idx, file_path in enumerate(files, 1):
            print(f"\n[{idx}/{len(files)}]", end=" ")
            self.upload_file(file_path)

            # Rate limiting ê³ ë ¤ (ì´ˆë‹¹ 60 requests)
            if idx % 50 == 0:
                print("\nâ¸ï¸  Rate limit ëŒ€ê¸° (60ì´ˆ)...")
                time.sleep(60)

        # ê²°ê³¼ ìš”ì•½
        self.print_summary()
        self.save_report()

    def print_summary(self) -> None:
        """ì—…ë¡œë“œ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        print("\n" + "=" * 60)
        print("ğŸ“Š ì—…ë¡œë“œ ê²°ê³¼ ìš”ì•½")
        print("=" * 60)
        print(f"âœ… ì„±ê³µ: {len(self.uploaded_files)}ê°œ")
        print(f"âŒ ì‹¤íŒ¨: {len(self.failed_files)}ê°œ")
        print(f"ğŸ“¦ Store: {self.store_name}")
        print(f"ğŸ”— Store ID: {self.store.name}")

        if self.failed_files:
            print("\nâŒ ì‹¤íŒ¨í•œ íŒŒì¼:")
            for failed in self.failed_files[:10]:  # ìµœëŒ€ 10ê°œë§Œ í‘œì‹œ
                print(f"   - {failed['file_path']}: {failed['error']}")
            if len(self.failed_files) > 10:
                print(f"   ... ì™¸ {len(self.failed_files) - 10}ê°œ")

    def save_report(self, output_file: str = "upload_report.json") -> None:
        """ì—…ë¡œë“œ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
        report = {
            'store_name': self.store_name,
            'store_id': self.store.name,
            'upload_time': datetime.now().isoformat(),
            'total_files': len(self.uploaded_files) + len(self.failed_files),
            'successful': len(self.uploaded_files),
            'failed': len(self.failed_files),
            'uploaded_files': self.uploaded_files,
            'failed_files': self.failed_files
        }

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)

        print(f"\nğŸ“„ ê²°ê³¼ ë³´ê³ ì„œ ì €ì¥: {output_file}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse

    parser = argparse.ArgumentParser(description='Gemini File Search RAG ì‹œìŠ¤í…œ - íŒŒì¼ ì—…ë¡œë“œ')
    parser.add_argument('directory', type=str, help='ì—…ë¡œë“œí•  ë””ë ‰í† ë¦¬ ê²½ë¡œ')
    parser.add_argument('--store-name', type=str, default='P5_Project_RAG_Store',
                        help='File Search Store ì´ë¦„')
    parser.add_argument('--max-files', type=int, default=None,
                        help='ìµœëŒ€ ì—…ë¡œë“œ íŒŒì¼ ìˆ˜')
    parser.add_argument('--report', type=str, default='upload_report.json',
                        help='ê²°ê³¼ ë³´ê³ ì„œ íŒŒì¼ëª…')

    args = parser.parse_args()

    # ì—…ë¡œë” ìƒì„± ë° ì‹¤í–‰
    uploader = GeminiRAGUploader(store_name=args.store_name)
    uploader.upload_directory(args.directory, max_files=args.max_files)
    uploader.save_report(args.report)


if __name__ == '__main__':
    main()
